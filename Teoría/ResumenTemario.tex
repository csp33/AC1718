\documentclass[12pt,spanish]{article}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage[hidelinks]{hyperref}
\usepackage{caption}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage[outputdir=build]{minted}
\usepackage{float}
\usepackage{titling}
\usepackage{soul}
\usepackage{listings}
\usepackage{array}
\graphicspath{ {./img/} {../../LaTeX/img/}}
\selectlanguage{spanish}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[a4paper,left=3cm,right=2cm,top=2.5cm,bottom=2.5cm]{geometry}
\renewcommand\listoflistingscaption{Códigos fuente}
\newtheorem*{definition}{Definición}
\newtheorem*{aclaration}{Aclaración}
\newtheorem{law}{Ley}
\newenvironment{solution}{
	\par
	\textbf{Solución}
	\par
	\begin{center}
}
{
	\end{center}
}

\title{Arquitectura de Computadores}
\setlength{\droptitle}{10em}
\author{Carlos Sánchez Páez}

\makeindex
\begin{document}


\begin{titlepage}

\newlength{\centeroffset}
\setlength{\centeroffset}{-0.5\oddsidemargin}
\addtolength{\centeroffset}{0.5\evensidemargin}
\thispagestyle{empty}

\noindent\hspace*{\centeroffset}
\begin{minipage}{\textwidth}

\centering
\includegraphics[width=0.9\textwidth]{logo_ugr.jpg}\\[1.4cm]

\textsc{ \Large Arquitectura de Computadores\\[0.2cm]}
\textsc{GRADO EN INGENIERÍA INFORMÁTICA}\\[1cm]

{\Huge\bfseries Resumen del temario\\}
\end{minipage}

\vspace{1.5cm}
\noindent\hspace*{\centeroffset}
\begin{minipage}{\textwidth}
\centering

\textbf{Autor}\\ {Carlos Sánchez Páez}\\[2.5ex]
\includegraphics[width=0.3\textwidth]{etsiit_logo.png}\\[0.1cm]
\vspace{1.5cm}
\includegraphics[width=0.5\textwidth]{atc_logo.jpg}\\[0.1cm]
\vspace{1cm}
\textsc{Escuela Técnica Superior de Ingenierías Informática y de Telecomunicación}\\
\vspace{1cm}
\textsc{Curso 2017-2018}
\end{minipage}
\end{titlepage}
\thispagestyle{empty}
\newpage
\tableofcontents{}
\listoflistings
\listoffigures
\thispagestyle{empty}
\newpage

\section{Tema 1}

\subsection{Arquitecturas paralelas y niveles de paralelismo}

\subsubsection{Niveles y tipos de paralelismo implementados en la arquitectura}
Un computador es un sistema complejo tanto desde el punto de vista del hardware como desde el del software.
Para que su estudio sea más sencillo, éste se divide en diferentes niveles de abstracción.\\
Por ejemplo, a nivel hardware, los niveles podrían ser: de componentes, de circuito electrónico, nivel de lógica digital, RT y nivel de sistema computador. En cada uno de estos niveles se implementa el paralelismo. \\
Para incrementar las prestaciones de un ssitema se aprovecha el paralelismo (explícito o implícito) en las entradas. Hay dos alternativas para implementar paralelismo en un sistema aprovechando las entradas:
\begin{enumerate}
\item \textit{Replicar} componentes del sistema.
\item \textit{Segmentar} el uso de los componentes.
\end{enumerate}
Por ejemplo, el paralelismo en un procesador se implementa replicando unidades funcionales y segmentando en uso de sus componentes. Los computadores paralelos son arquitecturas paralelas que implementan paralelismo \emph{a nivel de sistema computador}. Para ello, replican computadores.

\subsubsection{Niveles y tipos de paralelismo implícito en una aplicación}

En el mercado hay computadores que implementan paralelismo en varios niveles de la arquitectura. En una aplicación se pueden distinguir distintos niveles de paralelismo, que se aprovechan en diferentes niveles del computador. Podemos clasificar estos niveles según el nivel de abstracción dentro del código secuencial \footnote{Código escrito en lenguaje imperativo, próximo a las arquitecturas de flujo de control.} de un programa en el que podamos encontrar el paralelismo.

\paragraph{Dependencia de datos}
Antes de ver los tipos de paralelismo, veamos lo que son las dependencias de datos.
Para que el bloque de código $B_{2}$ presente una dependencia de datos con respecto a $B_{1}$:
\begin{enumerate}
\item Ambos bloques deben referenciar a una misma posición de memoria M (variable).
\item $B_{1}$ debe aparecer en el código antes que $B_{2}$
\end{enumerate}
\newpage
\subparagraph{Tipos de dependencias de datos}
\begin{enumerate}
\item \textbf{RAW}. Read After Write o \emph{dependencia verdadera}.

\begin{listing}[H]
\begin{minted}[linenos,xleftmargin=7cm,xrightmargin=7cm]{c}
...
a=b+c //[B1 escribe a]
d=a+c //[B2 lee a]
...
\end{minted}
\caption{Dependencia RAW}
\end{listing}

\item \textbf{WAW}. Write After Write o \emph{dependencia de salida}.

\begin{listing}[H]
\begin{minted}[linenos,xleftmargin=7cm,xrightmargin=7cm]{c}
...
a=b+c //[B1 escribe a]
a=d+e //[B2 escribe a]
...
\end{minted}
\caption{Dependencia WAW}
\end{listing}

\item \textbf{WAR}. Write After Read o \emph{antidependencia}.

\begin{listing}[H]
\begin{minted}[linenos,xleftmargin=7cm,xrightmargin=7cm]{c}
...
b=a+1 //[B1 lee a]
a=d+e //[B2 escribe a]
...
\end{minted}
\caption{Dependencia WAR}
\end{listing}

\end{enumerate}
\paragraph{Paralelismo funcional}
Podemos considerar que un programa está compuesto por funciones (nivel de funciones), éstas estñan compuestas por bucles (nivel de bucle) y éstos se basan en operaciones (nivel de operaciones). Como nivel superior encontramos al de programas, que pueden formar parte de la misma aplicación y usuario o no.\\
En general el paralelismo está implícito en mayor o menor grado en la descripción de una aplicación. Dentro del código secuencial podemos encontrar paralelismo implícito en los siguientes niveles de abstracción:
\begin{enumerate}
\item \emph{Nivel de programas}. Los diferentes programas que intervienen en una o varias aplicaciones se pueden ejecutar en paralelo. Es poco probable que exista dependencia entre ellos.
\item \emph{Nivel de funciones}. Un programa puede considerarse constituido por funciones. Se pueden ejecutar en paralelo, siempre que no haya dependencias (riesgos) inevitables entre ellas, como dependencias de datos verdaderas (lectura después de escritura, RAW, \textit{Read After Write}).
\emph{Nivel de bucle (bloques)}. Una función puede estar basada en la ejecución de uno o vasrios bucles. El código dentro de cada uno se ejecuta múltiples veces, completando una tarea en cada iteración. Se pueden ejecutar en paralelo las iteraciones de un bucle siempre que resolvamos los riesgos derivados de las dependencias verdaderas. Para detectarlas, tendremos que analizar las entradas y las salidas de las iteraciones del bucle.
\item \emph{Nivel de operaciones}. Se extrae el paralelismo disponible entre operaciones. Aquellas que son independientes se podrán ejecutar en paralelo. Por otra parte, en los procesadores podemos encontrar instrucciones compuestas de varias operaciones que se aplican en secuencia al mismo flujo de datos de entrada. Por tanto, podremos utilizar estas instrucciones compuestas para evitar penalizaciones por dependencias verdaderas.
\end{enumerate}
\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{paralelismo.png}
\caption{Niveles de paralelismo y granularidad}
\end{figure}
A este paralelismo que ese puede detectar en distintos niveles de un código secuencial se le denomina \emph{paralelismo funcional}.
\newpage
Por ejemplo:
\begin{listing}[H]
\begin{minted}[linenos,xleftmargin=4.5cm,xrightmargin=4.5cm]{c}
#include <stdio.h>
using namespace std;
int func1();
int func2();
int func3();
int main(){
	#pragma omp pararell sections{
		#pragma omp section
			func1();
		#pragma omp section
			func2();
		#pragma omp section
			func3();	
		}
}

\end{minted}
\caption{Paralelismo funcional}
\end{listing}

\paragraph{Paralelismo de tareas}

El \emph{paralelismo de tareas} se encuentra extrayendo de la definición de la aplicación la estructura lógica de funciones de la aplicación. En esta estruyctura, los bloques son funciones y las conexiones entre ellos reflejan el flujo de datos entre funciones. Analizando esta estructura podemos encotnrar paralelismo entre las funciones.\\
Está relacionado con el \textbf{paralelismo a nivel de función}.
\begin{figure}[H]
\centering
\includegraphics[scale=0.75]{paralelismo_tareas.png}
\caption{Paralelismo de tareas}
\end{figure}

\paragraph{Paralelismo de datos}

El \emph{paralelismo de datos} está relacionado con el \textbf{paralelismo a nivel de bucle}. Se encuentra implícito en las operaciones con estructuras de datos (vectores y matrices) y se puede extraer de una representación matemática de las operaciones de la aplicación. Por ejemplo, como vectores y matrices se operan mediante bucles, podremos implementarlas mediante paralelismo a nivel de bucle. Así aparece el paralelismo de datos al analizar las operaciones realizadas con la misma estructura de datos pero en distinta iteración.\footnote{Las instrucciones multimedia de los procesadores suelen acelerar el procesamiento vectorial ya que aplican la misma operación en paralelo a múltiples datos dentro de un registro.}\\
El paralelismo también se puede clasificar en función de la \emph{granularidad} o \emph{magnitud de la tarea} candidata a la paralelización. El grano más pequeño (\textit{grano fino}) se asocia generalmente al paralelismo entre operaciones o instrucciones y el \textit{grueso} al paralelismo entre programas. Entre ambos existe el \textit{grano medio}, asociado a los bloques funcionales lógicos de la aplicación.\\
Por ejemplo:
\begin{listing}[H]
\begin{minted}[linenos,xleftmargin=4.5cm,xrightmargin=4.5cm]{c}
#include <stdio.h>
using namespace std;
const int SIZE=100;
int main(){
int a[SIZE];
int b[SIZE];
int c[SIZE];
for(int i=0;i<SIZE;i++)
	a[i]=b[i]+c[i]
return 0
}
\end{minted}
\caption{Paralelismo de datos}
\end{listing}
\subsubsection{Unidades de ejecución: instrucciones, hebras y procesos}

En el nuvel superior, el sistema operativo se encarga de gestionar la ejecución de unidades de mayor granularidad (\textit{procesos} y \textit{hebras}). Cada proceso en ejecución tiene su propia región de memoria. Los sistemas operativos multihebra permiten que un proceso se componga de una o varias hebras.\\
La diferencia principal entre hebra y proceso es que una hebra tiene su propia pila y contenido de registros, entre ellos IP (\textit{Instruction Pointer}) que almacena la dirección de la siguiente instrucción a ejecutar por la hebra, pero comparte código, variables globales y otros recursos como archivos abiertos con el resto de hebras del mismo proceso. Estas características hacen que las hebras se puedan crear y destruir en menor tiempo que los procesos y que la comunicación, sincronización y conmutación entre hebras de un proceso sea más rápida que entre procesos. Esto permite que las hebras tengan una \textbf{granularidad menor que los procesos}.\\
El paralelismo implícito en el código de una aplicación se puede hacer \emph{explícito} a nivel de instrucciones, hebras, procesos o dentro de una instrucción.
\newpage
\subsubsection{Relación entre paralelismo implícito, explícito y arquitecturas paralelas}

El paralelismo se puede hacer explícito de varias formas:
\begin{enumerate}
\item El paralelismo \emph{entre programas} se utiliza a través de procesos. Cuando se ejecuta un programa, se crea su proceso asociado.
\item El paralelismo \emph{entre funciones} se puede utilizar a nivel de procesos o de hebras.
\item El paralelismo \emph{dentro de un bucle} también se puede utilizar a nivel de procesos o hebras. Además, podemos aumentar la granularidad asociando un mayor número de iteraciones a cada unidad de ejecución paralela. También se puede hacer explícito dentro de una instrucción vectorial.
\item El paralelismo \emph{entre operaciones} se puede aprovechar en arquitecturas con paralelismo a nivel de instrucción (\textit{ILP}), ejecutando en paralelo las instrucciones asociadas a las operaciones independientes.
\end{enumerate}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{paralelismo_implicito_explicito.png}
\caption{Paralelismo implícito, explícito y arquitecturas paralelas}
\end{figure}

\subsubsection{Detección, utilización, implementación y extracción de paralelismo}

En los procesadores \textit{ILP} superescalares o segmentados la arquitectura extrae paralelismo. Para ello, se eliminan dependencias de datos falsas entre instrucciones. En estos procesadores, la arquitectura extrae paralelismo \emph{implícito} en las entradas en tiempo de ejecución (\textit{dinámicamente}). El \textbf{grado de paralelismo} de las instrucciones aprovechado se puede incrementar con ayuda de \emph{compilador} y \emph{programador}. En general,\begin{definition}
El grado de paralelismo de un conjunto de entradas a un sistema es el máximo número de entradas del conjunto que se pueden ejecutar en paralelo.
\end{definition}
\begin{aclaration}
En el caso de los procesadores, las entradas son instrucciones.
\end{aclaration}
Debido a las dependencias entre entradas, este grado máximo será generalmente inferior al de entradas del conjunto. En las arquitecturas ILP VLIW \footnote{Instruction Level Parallelism Very Long Instruction Word} el paralelismo está ya \emph{explícito} en las entradas, ya que el paralelismo se determina fuera del hardware. En este caso, el análisis de dependencias es estático; el compilador es el principal responsable de extraer el paralelismo. No obstante, la ayuda de un prograamador puede incrementar el grado de concurrencia aprovechado finalmente por la arquitectura.\\
Para el compilador es difícil extraer el paralelismo, por lo que si el programador lo hace definiendo hebras y/o procesos se conseguirá mayor concurrencia.
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{deteccion_paralelismo.png}
\caption{Detección, utilización, implementación y extracción del paralelismo}
\end{figure}
\subsection{El paralelismo en las arquitecturas}
\subsubsection{Clasificaciones de las arquitecturas paralelas}
El paralelismo se ha implementado en las arquitecturas siguiendo dos líneas fundamentales. 
\begin{enumerate}
\item \textbf{Replicación de elementos}. Se incluyen unidades funcionales, procesadores, módulos de memoria, etc. entre los que se distribuye el trabajo. Ejemplos: multiprocesadores, procesadores de E/S, etc.
\item \textbf{Segmentación de cauce}. Consiste en dividir un elemento (unidad funcional, procesador, etc.) en una serie de etapas que funcionan de forma independiente y por las que pasan los operandos, instrucciones, etc. procesados por el elemento. Así, el elemento en cuestión realiza simultáneamente distintas etapas de su procesamiento.
\end{enumerate} 

La \textbf{clasificación \textit{(o taxonomía)} de Flynn} divide los computadores en cuatro clases según el número de secuencias o flujos \emph{de instrucciones} y flujos o secuencias \emph{de datos} que se pueden procesar simultáneamente en el computador.
\begin{enumerate}
\item \textbf{Computadores SISD} (\textit{Single Instruction Single Data}). Un único flujo de instrucciones genera resultados, definiendo un único flujo de datos.
\item \textbf{Computadores SIMD} (\textit{Single Instruction Multiple Data}). Un único flujo de instrucciones procesa operandos y genera resultados, defiendo varios flujos de datos, ya que cada instrucción codifica realmente varias operaciones iguales que actúan sobre operandos distintos.
\item \textbf{Computadores MIMD} (\textit{Multiple Instruction Multiple Data}). El computador ejecuta varias secuencias o flujos distintos de instrucciones y cada uno de ellos procesa operandos y genera resultados definiendo un único flujo de instrucciones, de forma que también se generan varios flujos de datos, uno por cada flujo de instrucciones.
\item \textbf{Computadores MISD} (\textit{Multiple Instruction Single Data}). Se ejecutan varios flujos distintos de instrucciones aunque todos actúan sobre el mismo flujo de datos.
\end{enumerate}

\begin{figure}[H]
\centering
\includegraphics[scale=1]{taxonomia_flynn.png}
\caption{Taxonomía de Flynn}
\end{figure}
\paragraph{SISD}
En un computador \textbf{SISD} existe una única unidad de control que recibe las instrucciones de memoria, las decodifica y genera los códigos que definen la operación correspondiente a cada instrucción que debe realizar la unidad de procesamiento. El flujo de datos se establece a partir de los operandos necesarios para realizar la operación correspondiente (se traen de memoria) y de los resultados generados por las instrucciones (se almacenan en memoria).

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{sisd.png}
\caption{Arquitectura SISD}
\end{figure}

\paragraph{SIMD}

En un computador \textbf{SIMD} los códigos que genera la única unidad de control a partir de cada instrucción actúan sobre varias unidades de procesamiento distintas. De esta forma, un computador SIMD puede realizar varias operaciones similares simultáneas con operandos distintos. Cada una de las secuencias de operandos y resultados utilizados por las distintas unidades de proceso definen un flujo de datos diferente.

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{simd.png}
\caption{Arquitectura SIMD}
\end{figure}

\paragraph{MIMD}

En un computador \textbf{MIMD} existen varias unidades de control que decodifican las instrucciones correspondientes a distintos programas. Cada uno de estos programas procesa conjuntos de datos diferentes, que constituyen distintos flujos de datos.

\begin{figure}[H]
\centering
\includegraphics[scale=1]{mimd.png}
\caption{Arquitectura MIMD}
\end{figure}

\paragraph{MISD}

Los computadores \textbf{MISD} forman una clase de computadores cuyo comportamiento se puede implementear con iguales prestaciones que en un computador MIMD en el que sus procesadores se sincronizan para que los datos vayan pasando desde un procesador a otro. Por tanto, si bien existen computadores SISD (monoprocesador), SIMD (procesadores matriciales y vectoriales) y MIMD (multiprocesadores y multicomputadores), los computadores MISD específicos no existen, ya que su forma de procesamiento se puede implementar en un MIMD.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{misd.png}
\caption{Arquitectura MISD}
\end{figure}

La taxonomía de Flynn pone de manifiesto dos tipos de paralelismo que pueden utilizarse: paralelismo de \emph{datos} y paralelismo de \emph{instrucciones}. El de \emph{datos} ese explota cuando una misma función, instrucción, etc. se ejecuta repetidas veces en paralelo con diferentes datos. Se explota fundamentalmente en las arquitecturas \textbf{MIMD}.\\
El paralelismo \emph{funcional} se aprovecha cuando las funciones, bloques, instrucciones, etc. (iguales o distintas) que intervienen en la aplicación se ejecutan en paralelo. 

\subsection{Espacio de diseño. Clasificación y estructura general}
\subsubsection{Clasificación}
Los sistemas de paralelismo de alto nivel se han clasificado en dos grupos en función de la organización de su espacio de direcciones:
\begin{enumerate}
\item \textbf{Sistemas con memoria compartida} (SM, \textit{Shared Memory}) o simplemente \textbf{multiprocesadores}. Son sistemas en los que todos los procesadores comparten el mismo espacio de direcciones. El programador no necesita saber dónde están almacenados los datos.
\item \textbf{Sistemas con memoria distribuida} (DM, \textit{Distributed Memory}) o \textbf{multicomputadores} . Cada procesador tiene su propio espacio de direcciones. El programador necesita saber dónde están almacenados los datos.
\end{enumerate}

En un procesador SMP (\textit{Symmetric MultiProcessor}) el tiempo de acceso de los procesadores a memoria o dispositivos de E/S será igual sea cual sea la posición a la que accedan. En estos procesadores , el acceso a memoria se realiza a través de la red de interconexión.\\
En los multicomputadores, cada procesador tiene su propio módulo de memoria local al que puede acceder directamente. En esta configuración la red de interconexión se utiliza para transferir mensajes entre nodos de la red. \\

\begin{table}[H]
\centering
\begin{tabular}{|m{3cm}|m{6cm}|m{6cm}|}
\hline
\textbf{Atributo} & 
\begin{center}
\textbf{Multiprocesador SMP} 
\\
\includegraphics[scale=0.2]{multiprocesador_smp.png} 
\end{center}
& 
\begin{center}
\textbf{Multicomputador} 
\\
\includegraphics[scale=0.2]{multicomputador.png} 
\end{center}
\\
\hline
Espacio de direcciones & Compartido por todos los procesadores & Cada procesador tiene el suyo \\
\hline
Programador & NO necesita saber dónde están almacenados los datos & Necesita saber dónde están almacenados los datos \\
\hline
Latencia en el acceso a memoria & Grande & Pequeña \\
\hline
Comunicación & Implícita mediante variables compartidas. Datos no duplicados & Explícita mediante
software para paso de mensajes. Datos duplicados. \\
\hline
Sincronización & Necesita implantar primitivas & Mediante software de comunicación \\
\hline
Distribución de código y datos entre procesadores & No necesaria & Necesaria \\
\hline
Programación & Sencilla & Complicada \\
\hline
\end{tabular}
\caption{Diferencias entre multicomputadores y multiprocesadores}
\end{table}
\paragraph{Incremento de escalabilidad en multiprocesadores y red de interconexión}
Se han seguido varios caminos para lograrlo:
\begin{enumerate}
\item Incorporar cachés para que cada procesador disponga de una caché local, reducciendo el número de accesos a memoria.
\newpage
\item Usar redes con menor latencia y mayor ancho de banda que un bus.
\begin{enumerate}
\item Jerarquía de buses.
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{jerarquia_buses.jpg}
	\caption{Jerarquía de buses}
	\end{figure}
\item Multietapa
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{multietapa.png}
	\caption{Multietapa}
	\end{figure}
\item Barras cruzadas. Proporciona el mejor rendimiento.
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{barras_cruzadas.png}
	\caption{Barras cruzadas}
	\end{figure}
\end{enumerate}
\item Distribuir físicamente los módulos de memoria principal entre los procesadores manteniendo el espacio de direcciones compartido. Se pierde la propiedad de la simetría.

\end{enumerate}

A raíz de la aparición de multiprocesadores con memoria físicamente distribuida surgieron nuevas denominaciones para sistemas con múltiples procesadores. Entonces los multiprocesadores se empezaron a clasificar según la uniformidad en el acceso a memoria:
\begin{enumerate}
\item \textbf{Multiprocesadores con acceso a memoria uniforme} o UMA (\textit{Uniform Memory Access}). El tiempo de acceso de los procesadores a una determinada posición de memoria principal (o caché) es igual sea cual sea el procesador (SMP).
\item \textbf{Multiprocesadores con acceso a memoria no uniforme} o NUMA (\textit{Non-Uniform Memory Access}). El tiempo de acceso depende del procesador.
\begin{enumerate}
\item \textbf{NCC-NUMA} (\textit{Non-Cache-Coherent Non-Uniform Memory Access}) o arquitecturas con acceso a memoria no uniforme sin coherencia de caché entre nodos o, simplemente, \textbf{NUMA}. En estas arquitecturas no hay hardware para evitar incoherencias entre cachés de distintos nodos. Esto hace que los datos modificables compartidos no se pueden trasladar a caché de nodos remotos, hay que acceder individualmente a ellos a través de la red.
\item \textbf{CC-NUMA} (\textit{Cache-Coherent Non-Uniform Memory Access}) o arquitecturas con acceso a memoria no uniforme y caché coherente. Tienen hardware para mantener la coherencia de caché, pero introduce un retardo que hace que la arquitectura escale en menor grado que un NUMA.
\item \textbf{COMA} (\textit{Cache Only Memory Access}) o arquitecturas con acceso a memoria solo caché. La memoria local se gestiona como caché e incluye un hardware de mantenimiento. El coste y el retardo de estos sistemas es mayor que en CC-Numa, por lo que no existe actualmente ningún sistema comercial COMA.
\end{enumerate}
\end{enumerate}
\subsubsection{Propuesta de clasificación de arquitecturas con múltiples threads}
\begin{itemize}
\item \textbf{TLP} (\textit{Thread Level Parallelism}). Múltiples flujos de control concurrentemente o en paralelo.
\begin{itemize}
\item \textbf{Implícito}. Flujos de control creados y gestionados por la arquitectura.
\item \textbf{Explícito}. Flujos de control creados y gestionados por el Sistema Operativo.
\begin{itemize}
\item \textbf{Con una instancia SO}. Multiprocesadores, multicores y cores multithread.
\item \textbf{Con múltiples instancias SO}. Multicomputadores.
\end{itemize}
\end{itemize}
\end{itemize}
\subsection{Evolución y prestaciones de las arquitecturas}
\subsubsection{Tiempo de CPU de un programa}
Para ilustrar el proceso de evolución de las arquitecturas se utiliza una expresión que relaciona el tiempo de CPU de un programa con tres características a través de las cuales podemos extraer consecuencias importantes relacionadas con la influencia de la tecnología, el compilador y la arquitectura en las prestaciones:
\begin{equation}
T_{tarea}=NI \cdot CPI \cdot T_{ciclo}=NI \cdot \frac{CPI}{f}
\end{equation}
\[
T_{ciclo}=\frac{1}{f}
\]
donde $T_{tarea}$ es el tiempo de CPU de un programa (también se puede notar como $T_{CPU}$), $NI$ es el número de instrucciones mñaquina del programa, $CPI$ es el número medio de ciclos por instrucción y $T_{ciclo}$ el período de reloj del procesador (inverso de la frecuencia, $f$). EL valor de CPI se puede expresar como:
\newpage
\begin{equation}
CPI=\frac{Ciclos_{programa}}{NI}=\frac{\sum_{i=1}^{n} CPI_{i} \cdot I_i}{NI}
\end{equation}
\[
Ciclos_{programa}=\sum_{i}^{n}CPI_i \cdot I_i
\]
donde $CPI_{i}$ es el número medio de ciclos de las instrucciones de tipo $i$ y $NI_{i}$ es el número de instrucciones de ese tipo.\\
Uno de los objetivos fundamentales en el diseño de un computador es reducir el tiempo de ejecución de los programas ($T_{tarea}$).\\
La ecuación (1) puede ayudarnos a comprender, por ejemplo, la diferencia entre RISC y CISC:
\begin{itemize}
\item En \textbf{CISC} se opta por reducir el $NI$ para reducir $T_{CPU}$, aunque aumenta el $CPI_i$. Sin embargo, este aumento se puede contrarrestar mejorando la frecuencia del procesador ($f$).
\item En \textbf{RISC} se opta por reducir el $CPI_i$ y aumentar el $NI_i$. Al igual que en el caso anterior, el aumento de $NI_i$ se puede contrarrestar mejorando $f$.
\end{itemize}
Hay procesadores que pueden emitir (mandar a ejecutar) varias instrucciones al mismo tiempo. En ese caso:
\[\frac{CPE}{IPE}=CPI\] 	
\begin{equation}
T_{CPU}=NI \cdot \frac{CPE}{IPE} \cdot T_{ciclo}
\end{equation}
donde $CPE$ es el número mínimo de ciclos transcurridos entre los instantes en los que el procesador puede emitir instrucciones y $IPE$ es el número de instrucciones que pueden emitirse en un instante.\\
También hay procesadores que pueden codificar varias operaciones en una instrucción:
\[NI=\frac{N_{operaciones}}{Operaciones_{instruccion}}\]
\begin{equation}
T_{CPU}=\frac{N_{operaciones}}{Operaciones_{instruccion}} \cdot CPI \cdot T_{ciclo}
\end{equation}
donde $N_{operaciones}$ es el número de operaciones que realiza el programa y $Operaciones_{instruccion}$ el número de operaciones que puede codificar una instrucción.
\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{optimizacion_t_cpu.png}
\caption{Optimizaciones del tiempo de CPU y sus causantes}
\end{figure}
\subsubsection{Medidas de productividad: MIPS y MFLOPS}
El tiempo de respuesta, la productividad y la funcionalidad se pueden englobar en una única medida de prestaciones, conocida como \emph{tiempo de respuesta para una entrada compleja}. Corresponde a una secuencia representativa de entradas elementales del sistema. En esta línea están los \emph{MIPS} y los \emph{MFLOPS}.
\paragraph{MIPS (Millions of Instructions Per Second)}
Vienen determinados por la siguiente fórmula:
\[T_{CPU}=NI \cdot CPI \cdot T_{ciclo} \]
\[f=\frac{1}{T_{ciclo}} \]
\begin{equation}
MIPS=\frac{NI}{T_{CPU} \cdot 10^6}=\frac{f}{CPI \cdot 10^6}
\end{equation}
Como podemos ver, esta medida puede variar según el programa, por lo que no sirve como medida característica de una máquina. Además, depende del repertorio de instrucciones, por lo que no permite comparar máquinas con repertorios distintos. Por último, puede ser inversamente proporcional a las prestaciones, ya que aquel programa que utilice más instrucciones tendrá más MIPS, indicando erróneamente que es mejor.
\subparagraph{\boldmath $MIPS_{pico}$}
Es el máximo valor téórico de MIPS para una arquitectura. Se calcula mediante la siguiente fórmula:
\begin{equation}
MIPS_{pico}=\frac{f \cdot IPC_{max}}{10^6}
\end{equation}
donde $IPC_{max}$ representa el número máximo de operaciones por ciclo que puede realizar la arquitectura.
\paragraph{MFLOPS (Millions of FLoating point Operations Per Second)}
Vienen definidos por:
\begin{equation}
MFLOPS=\frac{Operaciones_{coma flotante}}{T_{CPU} \cdot 10^6}
\end{equation}
Por un lado no es una medida adecuada para todos los programas, ya que solo tiene en cuenta las operaciones en coma flotante. Además, el conjunto de operaciones en coma flotante no es el mismo en todas las máquinas, así como el coste por operación. Para resolver este último problema, se utilizan a veces los MFLOPS normalizados, que se obtienen dando un peso relativo a cada instrucción.
\subparagraph{\boldmath $MFLOPS_{pico}$}
Se calculan mediante la siguiente expresión:
\begin{equation}
MFLOPS_{pico}=\frac{f \cdot \text{Operaciones en coma flotante/ciclo}_{max}}{10^6}
\end{equation}
\subsubsection{Conjuntos de programas de prueba (\textit{benchmarks})}

Para evaluar una arquitectura hay que considerar tanto las medidas de prestaciones que caracterizan a la arquitectura como las medidas de prestaciones que permiten comparar arquitecturas con \emph{igual uso}.\\
Para ello, se definen conjuntos de programas de prueba (\textit{benchmarks}) representativos de todos los posinlrd programas, representando la carga de trabajo usual en la máquina que los ejecutará. Hay de varios tipos:
\begin{enumerate}
\item \textbf{Aplicaciones reales}. Presentan problemas en cuanto a la portabilidad. Ejemplos: SPEC CPU2006
\item \textbf{Núcleos o \textit{kernels}}. Programas que evalúan una característica concreta. Resolución de sistemas de ecuaciones, multiplicación de matrices, etc.
\item \textbf{Programas de pruebas simples (\textit{toys})}. Son pequeños y fáciles de escribir. Test ping-pong, evaluación de operaciones con enteros y flotantes, etc.
\item \textbf{Programas sintéticos}. Dhrystone, Whetstone, etc. No realizan ninguna tarea concreta.
\item \textbf{Aplicaciones diseñadas}. Predicción del tiempo, simulación de terremotos, etc.
\subsubsection{Ganancia en prestaciones}
Si incrementamos las prestaciones de un computador mejorando alguno de sus recursos o elementos, podremos utilizar la \emph{ganancia} para evaluar hasta qué punto una mejora de prestaciones es \textit{p} veces mayor o menor que antes.\\
Este aumento de prestaciones se expresa mediante la ganancia de velocidad ($S_p$, \textit{Speed Up})
\begin{equation}
S_p=\frac{T_1}{T_p}=\frac{V_p}{V_1}
\end{equation}
donde:
\begin{itemize}
\item $V_1$ es la velocidad de la máquina base.
\item $V_p$ es la velocidad de la máquina mejorada.
\item $T_1$ es el tiempo de ejecución en la máquina base.
\item $T_p$ es el tiempo de ejecución en la máquina mejorada.
\end{itemize}
\end{enumerate}

Surge la cuestión de hasta qué punto la mejora en un factor \emph{p} se pone de manifiesto en la mejora final objetiva, surgiendo así la \textbf{Ley de Amdahl}.
\begin{law}[de Amdahl]
La mejora de velocidad, $S_p$ que se puede obtener al mejorar un recurso de una máquina en un factor $p$ está limitada por la expresión:
\[ S_p \leq \frac{p}{1 + f \cdot (p-1)} \]
\end{law}
donde $f$ es el porcentaje de operaciones que realiza la máquina en las que no se pone de manifiesto la mejora (por supuesto, $0 \leq f \leq 1$). Así, solo si $f=0$ (la mejora se utiliza siempre) una mejora de factor $p$ en un elemento se observa n la misma medida en la máquina.
\subparagraph{Ejemplo}
Si un programa pasa un $25\%$ del tiempo de ejecución realizando operaciones de coma flotante y mejoramos la máquina haciendo que esas instrucciones se ejecuten en la mitad de tiempo ($p=2$);
\[ S_p \leq \frac{2}{1 + 0.75 \cdot (2-1)} \leq \frac{2}{1.75} \leq 1.14\]
Es decir, la mejora en la arquitectura completa será de sólo un $14\%$.
\subsection{Ejercicios}
\begin{enumerate}
\item Calcule los $MIPS_{pico}$ de una arquitectura con una CPU superescalar con un IPC de 3 instrucciones por ciclo y una frecuencia de 2Ghz.
\begin{solution}
\[ MIPS_{pico}=\frac{2 \cdot 10^9 ciclos/seg \cdot 3 instrucciones/ciclo}{10^6}=6 \cdot 10^3 \ MIPS \simeq 6 \ GIPS \]
\end{solution}
\item En el  código de  prueba  (benchmark) que  ejecuta un procesador  no  segmentado  que  funciona a 300  MHz,  hay  un  20\%  de  instrucciones  LOAD  que  necesitan  4  ciclos,  un  10\%  de  instrucciones  STORE  que necesitan  3  ciclos,  un  25\%  de  instrucciones  con  operaciones  de  enteros  que  necesitan  6  ciclos,  un  15\%  de instrucciones  con  operandos  en  coma  flotante  que  necesitan  8  ciclos  por  instrucción,  y  un  30\%  de instrucciones de salto que necesitan 3 ciclos. 
\begin{enumerate}
\item ¿Cuál es la ganancia que se puede obtener por reducción a 3 ciclos de las instrucciones con enteros?
\item ¿Cuál es la ganancia que se puede obtener por reducción a 3 ciclos de las instrucciones en coma flotante?
\end{enumerate}
\begin{solution}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{Porcentaje de uso} & \textbf{CPI} \\
\hline
LOAD & 20\% & 4 \\
\hline
STORE & 10\% & 3 \\
\hline
Operaciones con enteros & 25\% & 6 \\
\hline
Operaciones en coma flotante & 15\% & 8 \\
\hline
Salto & 30\% & 3 \\
\hline
\end{tabular}
\par
\bigskip
Antes de la optimización
\end{table}
\newpage
\begin{itemize}
\item Apartado a)
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{Porcentaje de uso} & \textbf{CPI} \\
\hline
LOAD & 20\% & 4 \\
\hline
STORE & 10\% & 3 \\
\hline
Operaciones con enteros & 25\% & \textst{6} 3 \\
\hline
Operaciones en coma flotante & 15\% & 8 \\
\hline
Salto & 30\% & 3 \\
\hline
\end{tabular}
\par
\bigskip
Tras la optimización
\end{table}
Como el CPI de las operaciones con enteros se reduce a la mitad, $p=2$.\\
Aplicamos la ley de Amdahl:
\[ S_p=\frac{p}{1 + f \cdot (p-1)} \rightarrow S_p = \frac{2}{1 + 0.75 \cdot (2-1)}= \frac{2}{1.75} \simeq  1.143 \]
\begin{center}
Por tanto la mejora será de aproximadamente el $14,3\%$
\end{center}
\item Apartado b)

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{Porcentaje de uso} & \textbf{CPI} \\
\hline
LOAD & 20\% & 4 \\
\hline
STORE & 10\% & 3 \\
\hline
Operaciones con enteros & 25\% & 6 \\
\hline
Operaciones en coma flotante & 15\% & \textst{8} 3 \\
\hline
Salto & 30\% & 3 \\
\hline
\end{tabular}
\par
\bigskip
Tras la optimización
\end{table}
Como el CPI de las operaciones en coma flotante pasa de 8 a 3, $p=\frac{8}{3}=2.67$.
Aplicamos la Ley de Amdahl
\[S_p=\frac{p}{1 + f \cdot (p-1)} \rightarrow S_p=\frac{2.67}{1 + 0.85 \cdot (2.67-1)}=\frac{2,67}{1.4195} \simeq 1.88
\]
Por tanto, la mejora es aproximadamente del $88\%$

\end{itemize}

\end{solution}
\item En  un  procesador  sin  segmentación  de  cauce,  determine  cuál  de  estas  dos  alternativas  para realizar un salto condicionales mejor:
\begin{enumerate}
\item Una instrucción COMPARE actualiza un código de condición y es seguida por una instrucción BRANCH que comprueba esa condición.Se usan dos intrucciones.
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{NI} & \textbf{CPI} \\
\hline
COMPARE & $0.2NI_1$ & 4 \\
\hline
Resto & $0.8NI_1$ & 3 \\
\hline
& $NI_1$ & \\
\hline
\end{tabular}
\end{table}
\item Una sola instrucción incluye la funcionalidad de las instrucciones COMPARE y BRANCH.Se usa una única instrucción.
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{NI} & \textbf{CPI} \\
\hline
COMPARE + BRANCH & $0.2NI_1$ & 4 \\
\hline
Resto & $0.8NI_1-0.2NI_1=0.6NI_1$ & 3 \\
\hline
& $0.8NI_1$ & \\
\hline
\end{tabular}
\end{table}
\end{enumerate}
Hay que tener en cuenta que hay un 20\% de instrucciones BRANCH para a) en el conjunto de programas de prueba; que las instrucciones BRANCH en a) y COMPARE+BRANCH en b) necesitan 4  ciclos mientras que todas las demás necesitan sólo 3; y que el ciclo de reloj de la a) es un 25\% menor que el de la b), dado que en  éste caso la mayor funcionalidad de la instrucción COMPARE+BRANCH ocasiona una mayor complejidad en el procesado.
\begin{solution}
\textbf{Considero que en el apartado a) la instrucción BRANCH entra en el resto, por lo que consume 3 CPI.}\\
Sabemos que $T_{ciclo1}=0.75 \cdot T_{ciclo2} \rightarrow T_{ciclo2}=1.33 \cdot T_{ciclo1}$
Ahora calculamos los $T_{CPU}$. Para ello, comenzamos por los $CPI_i$
\begin{itemize}
\item $CPI_1=\frac{0.2\cdot NI_1}{NI_1} \cdot 4 + \frac{0.8 \cdot NI_1}{NI_1} \cdot 3 = 3.2$ 
\item $T_{CPU1}=NI_1 \cdot CPI_1 \cdot T_{ciclo1}= 3.2 \cdot NI_1 \cdot T_{ciclo1}$
\item $CPI_2=\frac{0.2\cdot NI_1}{0.8 \cdot NI_1} \cdot 4 + \frac{0.6 \cdot NI_1}{0.8 \cdot NI_1} \cdot 3 = 3.25$ 
\item $T_{CPU2}=0.8 \cdot NI_1 \cdot 3.25 \cdot 1.33 \cdot T_{ciclo1}= 3.45 \cdot NI_1 \cdot T_{ciclo1}$
\end{itemize}
Como $T_{CPU1} < T_{CPU2} $, la mejor opción es la \textbf{a)}.

\end{solution}
\item ¿Qué ocurriría en el ejercicio anterior si el ciclo de reloj fuese únicamente un 10\% mayor para b) ?
\begin{solution}
El problema nos indica que $T_{ciclo2}=1.1T_{ciclo1}$
\[T_{CPU1}=3.2 \cdot NI_1 \cdot T_{ciclo1}\]
\[T_{CPU2}=(0.8 \cdot 3.25 \cdot 1.1)NI_1 \cdot T_{ciclo1}=2.86 \cdot NI_1 \cdot T_{ciclo1}\]
En este caso, $T_{ciclo2} < T_{ciclo1}$, por lo que la opción \textbf{b)} se convierte en la mejor.
\end{solution}
\item Considere un procesador no segmentado con una arquitectura de tipo LOAD/STORE en la que las operaciones   sólo   utilizan   como   operandos   registros   de   la   CPU.   Paraun   conjunto   de   programas representativos de su actividad se tiene que el 43\% de las instrucciones son operaciones con la ALU (3 CPI), el 21\% LOADs (4 CPI), el 12\% STOREs (4 CPI) y el 24\% BRANCHs (4 CPI).Se ha podido comprobar que un 25\% de las operaciones con la ALU utilizan operandos en registros que no se vuelven  a  utilizar. Compruebe  si  mejorarían  las  prestaciones si,  para  sustituir  ese  25\%  de  operaciones,se añaden instrucciones con un dato en un registro y otro en memoria. Tengan en cuenta en la comprobación que para estas nuevas instrucciones el valor de CPI es 4 y que añadirlas ocasiona un incremento de un ciclo en el CPI de los BRANCHs, pero no afectan al ciclo de reloj.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{NI} & \textbf{CPI} \\
\hline
ALU (R-R) & $0.43NI_1$ & 3 \\
\hline
LOAD & $0.21NI_1$ & 4 \\
\hline
STORE & $0.12NI_1$ & 4 \\
\hline
BRANCH & $0.24NI_1$ & 4 \\
\hline
& $NI_1$ & \\
\hline
\end{tabular}
\caption*{Antes de la mejora}
\end{table}
\begin{solution}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{NI} & \textbf{CPI} \\
\hline
ALU (R-R) & $0.75 \cdot 0.43NI_1=0.3225NI_1$ & 3 \\
\hline
ALU (R-M) & $0.25 \cdot 0.43NI_1=0.1075NI_1$ & 4 \\
\hline
LOAD & $0.21NI_1 - 0.25 \cdot 0.43NI_1=0.1025NI_1$ & 4 \\
\hline
STORE & $0.12NI_1$ & 4 \\
\hline
BRANCH & $0.24NI_1$ & \textst{4} 5 \\
\hline
& $0.8925NI_1$ & \\
\hline
\end{tabular}
\caption*{Tras la mejora}
\end{table}
Calulamos el tiempo de CPU de ambas situaciones:
\[CPI_1=\frac{0.43NI_1}{NI_1}\cdot 3 + \frac{0.21NI_1}{NI_1} \cdot 4 + \frac{0.12NI_1}{NI_1} \cdot 4 + \frac{0.24NI_1}{NI_1} \cdot 4 = 3.57\]
\[T_{CPU1}=CPI_1 \cdot NI_1 \cdot T_{ciclo1}= 3.57NI_1 \cdot T_{ciclo1} \]

\[CPI_2=\frac{0.3225NI_1}{0.8925NI_1}\cdot 3 + \frac{0.1075NI_1}{0.8925NI_1} \cdot 4 + \frac{0.21NI_1}{0.8925NI_1} \cdot 4 + \frac{0.12NI_1}{0.8925NI_1} \cdot 4 + \frac{0.24NI_1}{0.8925NI_1} \cdot 4 = 3.91\]
\[T_{CPU2}=3.91 \cdot 0.8925NI_1 \cdot T_{ciclo2}= 3.49NI_1 \cdot T_{ciclo1} \]
Como $T_{CPU2}<T_{CPU1}$; la mejora \textbf{es efectiva}.
\end{solution}
\newpage
\item Se  ha  diseñado un compilador para la máquina LOAD/STORE del problema anterior. Ese compilador puede reducir en un 50\% el número de operaciones con la ALU, pero no reduce el número de LOADs, STOREs y BRANCHs. Suponiendo que la  frecuencia de reloj es de 50 Mhz. ¿Cuál es el número de MIPS y el tiempo de   ejecución que se consigue con el código optimizado? Compárelos con los correspondientes del código no optimizado.
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{NI} & \textbf{CPI} \\
\hline
ALU (R-R) & $0.43NI_1$ & 3 \\
\hline
LOAD & $0.21NI_1$ & 4 \\
\hline
STORE & $0.12NI_1$ & 4 \\
\hline
BRANCH & $0.24NI_1$ & 4 \\
\hline
& $NI_1$ & \\
\hline
\end{tabular}
\caption*{Antes de la mejora}
\end{table}
\begin{solution}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Instrucción} & \textbf{NI} & \textbf{CPI} \\
\hline
ALU (R-R) & $\frac{0.43NI_1}{2}$ & 3 \\
\hline
LOAD & $0.21NI_1$ & 4 \\
\hline
STORE & $0.12NI_1$ & 4 \\
\hline
BRANCH & $0.24NI_1$ & 4 \\
\hline
& $0.785NI_1$ & \\
\hline
\end{tabular}
\caption*{Tras la mejora}
\end{table}

Comenzamos calculando el Tiempo de CPU
\[
CPI_1=\frac{0.43NI_1}{NI_1}\cdot 3 + \frac{0.21NI_1}{NI_1}\cdot 4 + \frac{0.12NI_1}{NI_1}\cdot 4 + \frac{0.24NI_1}{NI_1}\cdot 4 =3.57
\]
\[
CPI_2=\frac{\frac{0.43NI_1}{2}}{0.785NI_1}\cdot 3 + \frac{0.21NI_1}{0.785NI_1}\cdot 4 + \frac{0.12NI_1}{0.785NI_1}\cdot 4 + \frac{0.24NI_1}{0.785NI_1}\cdot 4 =3.726
\]
\[T_{CPU1}=NI_1 \cdot T_{ciclo} \cdot CPI_1=3.57 \cdot NI_1 \cdot T_{ciclo}
\]
\[T_{CPU2}=0.785NI_1  \cdot CPI_2 \cdot T_{ciclo}=0.785NI_1 \cdot 3.726 \cdot T_{ciclo}=2.925 \cdot T_{ciclo}
\]
Ahora, calculamos MIPS
\begin{adjustbox}{width=\textwidth,totalheight=\textheight,keepaspectratio}
$MIPS_1=\frac{NI_1}{T_{CPU1} \cdot 10^6}=\frac{NI_1}{NI_1 \cdot CPI_1 \cdot T_{ciclo} \cdot 10^6}=\frac{f}{CPI_1 \cdot 10^6}=\frac{50 ciclos/segundo \cdot 10^6}{3.57 ciclos/instruccion \cdot 10^6}=14.005 MIPS
$
\end{adjustbox}
\begin{adjustbox}{width=\textwidth,totalheight=\textheight,keepaspectratio}
$MIPS_2=\frac{0.785NI_1}{T_{CPU2} \cdot 10^6}=\frac{NI_1}{0.785NI_1 \cdot CPI_2 \cdot T_{ciclo} \cdot 10^6}=\frac{f}{CPI_2 \cdot 10^6}=\frac{50 ciclos/segundo \cdot 10^6}{3.726 ciclos/instruccion \cdot 10^6}=13.42 MIPS
$
\end{adjustbox}
\par
La configuración 2 tiene un tiempo de CPU \textbf{mejor}. Sin embargo, si miramos la productividad, vemos como es \textbf{peor}. Esto se debe a que el sistema es más rápido, pero menos productivo, ya que la mejora se ha implementado en la parte que menos se usa.
\end{solution}
\end{enumerate}

\section{Tema 2}

\subsection{Programación paralela}

La programación paralela introduce un conjunto de problemas para el programador: división del trabajo en unidades independientes (tareas), sincronización, comunicación, etc.\\

Actualmente, las herramientas y métodos para facilitar el desarrollo de aplicaciones paralelas existentes son un activo campo de investigación. Para el programador lo más sencillo es utilizar compiladores capaces de extraer paralelismo automáticamente. Sin embargo, estos compiladores no generan código eficiente para todos los programas. Por tanto, no sirven de mucho.\\


\subsubsection{Punto de partida}

Cuando se plantea obtener una versión paralela de una aplicación, podemos utilizar como punto inicial un código secuencial que resuelva el problema para implantar el paralelismo sobre él. La principal ventaja de esta opción es la posibilidad de medir el tiempo en cada sección, permitiendo distribuir el trabajo de forma equilibrada.\\

Otra posibilidad es partir de la definición de una aplicación y buscar a partir de ella una descripción que admita paralelización.\\

Para facilitar el trabajo podemos apoyarnos en programas paralelos que aprovechen las características de la arquitectura. Si disponemos de un programa paralelo que resuelve un problema parecido en una arquitectura, podemos fijarnos en él para diseñar el nuestro.

\subsubsection{Modos de programación}

\paragraph{SPMD (paralelismo de datos)}
Todos los códigos que se ejecutan en paralelo se obtienen compilando el mismo programa. Cada copia trabaja con un conjunto de datos distintos y se ejecuta en un procesador diferente.

\paragraph{MPMD} 
Los códigos que se ejecutan en paralelo se obtienen compilando programas independientes, es decir, la aplicación principal se divide e unidades independientes. Cada unidad trabaja con un conjunto de ddatos y es asignada a un procesador.\\

SPMD es recomendable en sistemas masivamente paralelos, ya que es muy difícil encontrar cientos de unidades de código diferentes dentro de una aplicación, siendo más fácil escribir un sólo programa. En la práctica es el más utilizado en multiprocesadores y multicomputadores.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{spmd.png}
\caption{SPMD (Single Program Multiple Data).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{mpmd.png}
\caption{MPMD (Multiple Program Multiple Data).}
\end{figure}

\subsubsection{Herramientas para obtener programas paralelos}

Las herramientas para obtener programas paralelos deben permitir de forma explícita (el trabajo lo hace el programador) o implícita (el trabajo lo hace la propia herramienta) las siguientes tareas:

\begin{itemize}
	\item Localizar paralelismo.
	\item Crear y terminar procesos.
	\item Distribuir trabajo entre procesos.
	\item Comunicación y sincronización entre procesos.
	\item Asignación de procesos a procesadores.
\end{itemize}

Para obtener un programa paralelo tenemos varias opciones:

\paragraph{Bibliotecas de funciones para programación paralela}

En esta alternativa el programador utiliza un lenguaje secuencial y una biblioteca de funciones. El cuerpo de los procesos y hebras se escribe con lenguaje secuencial y el programador se encarga explícitamente de dividir las tareas entre los procesos, crear o destruir los procesos, implementar la comunicación, etc. Las principales ventajas de esta alternativa son:
\begin{itemize}
	\item Los programadores no tienen que aprender un nuevo lenguaje.
	\item Las bibliotecas están disponibles para todos los sistemas paralelos.
	\item Las bibliotecas están más cercanas al hardware y dan al programador un control a más bajo nivel.
	\item Se pueden utilizar a la vez bibliotecas para programar con hebras y bibliotecas para programar con procesos.
\end{itemize}

Las APIs más famosas son MPI, OpenMP, Pthread, etc.

\paragraph{Lenguajes paralelos y directivas del compilador}

Sitúan al programador en un nivel de abstracción superior, ahorrando o facilitando el trabajo de paralelización, aunque puede que sólo se aproveche uno de ellos: de datos o de tareas. Los lenguajes paralelos facilitan estas tareas mediante:
\begin{itemize}
	\item Construcciones propias del lenguaje. Pueden tanto distribuir la carga de trabajo como crear y terminar procesos e incluir sincronización.
	\item Directivas del compilador.
	\item Funciones de biblioteca. Implementan en paralelo algunas operaciones usuales.
\end{itemize}

La ventaja principal de los lenguajes paralelos es que son más fáciles de escribir y entender a la vez que más cortos.

\paragraph{Compiladores paralelos}

Se pretende que un compilador paralelo extraiga automáticamente el paralelismo tanto a nivel de bucle (paralelismo de datos) como a nivel de función (paralelismo de tareas). Para ello, hacen análisis de dependencias entre bloques de código, iteraciones de un bucle o funciones. Las dependencias que detecta son RAW, WAW y WAR.\\

Los compiladores paralelos están aún limitados a aplicaciones que exhiben un paralelismo regular, como los cálculos a nivel de bucle.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{herramientas_programacion_paralela.png}
\caption{Principales herramientas de programación paralela.}
\end{figure}

\paragraph{Otras alternativas}

\subparagraph{Comunicación múltiple uno a uno}
Hay componentes del grupo que envían un único mensaje (dato o estructura de datos) y componentes que reciben un único lenguaje.\\

Si todos los componentes envían y reciben, se implementa una \emph{permutación}. Algunos ejemplos de permutaciones son la rotación, el intercambio, los barajes, etc.

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{uno_a_uno.png}
\caption{Comunicación uno a uno.}
\end{figure}

\subparagraph{Comunicación uno a todos}


Un proceso envía u todos los procesos reciben. Hay variantes en las que el proceso que envía no forma parte del grupo y otras en las que reciben todos excepto el que envía. Hay dos subtipos:

\begin{itemize}
	\item \textbf{Difusión}. Todos los procesos reciben el mismo mensaje.
	\item \textbf{Dispersión (\textit{scatter})}. Cada proceso receptor recibe un mensaje diferente.	
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{uno_a_todos.png}
\caption{Comunicación uno a todos.}
\end{figure}


\subparagraph{Comunicación todos a uno}

Todos los procesos del grupo envían un mensaje a un único proceso.

\begin{itemize}
	\item \textbf{Reducción}. Los mensajes enviados por los procesos se combinan en un solo mensaje mediante algún operador. La combinación es normalmente conmutativa y asociativa.
	\item \textbf{Acumulación (\textit{gather})}. Los mensajes se reciben de forma concatenada en el receptor. El orden en que se concatenan depende normalmente del identificador de proceso.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{todos_a_uno.png}
\caption{Comunicación todos a uno.}
\end{figure}

\subparagraph{Comunicación todos a todos}

Todos los procesos del grupo ejecutan una comunicación \emph{uno a todos}. Cada proceso recibe \textit{n} mensajes, cada uno de un proceso diferente del grupo.

\begin{itemize}
	\item \textbf{Todos difunden (\textit{all-broadcast})}. Todos los procesos realizan una difusión. Normalmente las transferencias recibidas por un proceso se concatenan según el identificador de proceso.
	\item \textbf{Todos dispersan (\textit{all-scatter})}. Los procesos concatenan diferentes transferencias. En el ejemplo se muestra una trasposición de una matriz 4x4. Cada procesador $P_i$ dispersa la fila $i(x_{i0},x_{i1},...)$. Tras la ejecución, $P_i$ tendrá la columna $i(x_{0i},x_{1i},...)$.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{todos_a_todos.png}
\caption{Comunicación todos a todos.}
\end{figure}

\subparagraph{Comunicaciones colectivas compuestas}

Las comunicaciones anteriores se pueden combinar dando lugar a nuevos servicios:

\begin{itemize}
	\item \textbf{Todos combinan o reducción y extensión}. Se aplica una reducción a todos los procesos, ya sea difundiéndola una vez obtenida (reducción y extensión) o bien realizándola en todos los procesos (todos combinan).
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{todos_combinan.png}
		\caption{Todos combinan.}
	\end{figure}
	\item \textbf{Barrera}. Es un punto de sincronización que todos los procesos de un grupo deben alcanzar para poder continuar su ejecución. Se puede implementar mediante cerrojos o a nivel software.
	\item \textbf{Recorrido (\textit{scan})}. Todos los procesos envían un mensaje, recibiendo cada uno el resultado de reducir un conjunto de esos mensajes.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{scan.png}
		\caption{Recorrido (\textit{scan}).}
	\end{figure}
\end{itemize}
	
\subsubsection{Estilos de programación}

\paragraph{Paso de mensajes}

Disponemos de dos funciones principales:
\begin{itemize}
	\item \textbf{send(destino,datos)}. Envía datos.
	\item \textbf{receive(fuente,datos)}. Recibe datos.
\end{itemize}

Por lo general podemos encontrar transmisiones \emph{síncronas} (cuando ejecutamos un \emph{send}, el proceso se bloquea hasta que el destino recibe el dato y viceversa con \emph{receive}) o \emph{asíncronas} (\emph{send} no bloquea, por lo que suele hacerlo \emph{receive}).

La interfaz más conocida de paso de mensajes es MPI.

\paragraph{Variables compartidas}

La comunicación entre procesos se realiza accedeiendo a variables compartidas, es decir, mediante accessos y escrituras en memoria. Las hebras de un proceso creadas por el sistema operativo pueden compartir inmediatamente variables globales, pero los procesos no (tienen diferentes espacios de direcciones). En este caso, hemos de utilizar llamadas al sistema específicas.\\

La exclusión mutua se puede implementar mediante cerrojos, semáforos, variables condicionales, monitores, etc.\\

La interfaz más utilizada es OpenMP. Hay lenguajes, como Java, que implementan este paradigma.

\paragraph{Paralelismo de datos}

En este estilo se aprovecha el paralelismo de datos inherente a aplicaciones en las que los datos se organizan en estructuras (vectores o matrices). El programador escribe un programa con construcciones que permiten aprovechar el paralelismo: construcciones para paralelizar bucles, para distribuir datos, etc. Por tanto, no ha de ocuparse de las sincronizaciones, ya que son implícitas.\\

El lenguaje con paralelismo de datos más conocido es C* (\textit{C star}). En cuanto a APIs, destaca \textit{Nvidia CUDA}.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.3]{estilos_programacion.png}
	\caption{Estilos de programación paralela.}
\end{figure}

\subsubsection{Estructuras de programas paralelos}

\paragraph{Dueño-esclavo (\textit{master-slave}) o granja de tareas (\textit{task-farming})}

Consta de un dueño y varios esclavos. El dueño se encarga de distribuir las tareas de un conjunto (granja) entre el grupo de esclavos y de ir recogiendo los resultados parciales que van calculando los esclavos. El dueño calcula el resultado final a partir de estos resultados parciales. Normalmente no hay comunicación entre los esclavos.\\

Se puede implemenmtar de forma mixta MPMD-SPMD con un programa para el dueño y otro para los esclavos o bien mediante SPMD con un sólo programa para ambos.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.25]{maestro_esclavo.png}
	\caption{Dueño-esclavo.}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\textwidth}
\begin{minted}[linenos]{c++}
int main(){
/**Código dueño***/
}
--------------
int main(){
/**Código esclavo***/
}
\end{minted}
\caption{Dueño-esclavo como MPMD-SPMD}
\end{subfigure}
\hspace{5cm}
\begin{subfigure}[b]{0.3\textwidth}
\begin{minted}[linenos]{c++}
int main(){
 if(id_proc==id_duenio){
  /**Código dueño**/
 }
 else{
  /**Código esclavo**/
 }
}
\end{minted}
\caption{Dueño-esclavo como MPMD-SPMD}
\end{subfigure}
\caption{Diferentes implementaciones de dueño-esclavo.}
\end{figure}

\paragraph{Paralelismo de datos o descomposición de datos}

Esta alternativa se utiliza para obtener tareas paralelas en problemas en los que se opera con grandes estructuras de datos. La estructura de datos de entrada o la de salida (o ambas) se dividen en partes, de las que derivarán las tareas paralelas.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.25]{descomposicion_datos.png}
	\caption{Descomposición de datos.}
\end{figure}

\paragraph{Divide y Vencerás}

Consiste en dividir un problema en dos o más subproblemas de forma que cada uno se pueda resolver de forma independiente y combinar los resultados para obtener el resultado final. Si los subproblemas son instancias más pequeñas que el original, podremos implementarlo mediante recursividad.

\begin{figure}[H]
\begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{dyv.png}
\end{subfigure}
\quad
\begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{dyv_2.png}
\end{subfigure}
\caption{Divide y Vencerás.}
\end{figure}

\paragraph{Cliente-servidor}

Los clientes realizan peticiones a un servidor y éste les envía las respuestas.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.25]{cliente_servidor.png}
	\caption{Cliente-servidor.}
\end{figure}

\paragraph{Segmentada (\textit{pipeline}) o flujo de datos}

Aparece en probelmas en los que se aplican distintas funciones a un mismo flujo de datos (paralelismo de tareas). La estructura de procesos y de tareas es la de un cauce segmentado, por lo que cada proceso ejecuta distinto código (MPMD).

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{segmentada.png}
	\caption{Segmentada (\textit{pipeline}). Decodificación JPEG.}
\end{figure}


\subsection{Proceso de paralelización}

\subsubsection{Descomposición de tareas}


\subsubsection{Asignar tareas a procesos o hebras}


\subsubsection{Escribir el código paralelo}


\subsubsection{Evaluación de prestaciones}



\subsection{Prestaciones en computadores paralelos}

\subsubsection{Benchmark en computadores paralelos}


\subsubsection{Ganancia en prestaciones. Escalabilidad}


\subsubsection{Ejercicios}




\end{document}